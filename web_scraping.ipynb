{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMgqwSvUG9lDgdSLr3t0f16",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ranaem/Wuzzuf-Jobs-Analysis/blob/main/web_scraping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " # **Web Scraping for Wuzzuf**"
      ],
      "metadata": {
        "id": "diNIGDNQvpLW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RoNPVo-IspR9"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_url = \"https://wuzzuf.net/search/jobs/?q=IT/Software%20Development\"\n",
        "\n",
        "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"}\n",
        "\n",
        "# وظيفة لجمع البيانات من صفحة واحدة\n",
        "def get_jobs_from_page(url):\n",
        "    response = requests.get(url, headers=headers)\n",
        "    soup = BeautifulSoup(response.content, \"lxml\")\n",
        "\n",
        "    jobs = []\n",
        "    for job_card in soup.find_all(\"div\", class_=\"css-1gatmva e1v1l3u10\"):\n",
        "        try:\n",
        "            title = job_card.find(\"h2\", class_=\"css-m604qf\").text.strip()  # عنوان الوظيفة\n",
        "            company = job_card.find(\"a\", class_=\"css-17s97q8\").text.strip()  # اسم الشركة\n",
        "            location = job_card.find(\"span\", class_=\"css-5wys0k\").text.strip()  # الموقع\n",
        "            date = job_card.find(\"div\", class_=\"css-do6t5g\").text.strip()  # تاريخ النشر\n",
        "            skills = job_card.find(\"div\", class_=\"css-y4udm8\").text.strip()  # المهارات المطلوبة\n",
        "            link = \"https://wuzzuf.net\" + job_card.find(\"a\", class_=\"css-o171kl\")[\"href\"]  # رابط الوظيفة\n",
        "            jobs.append({\"Job Title\": title, \"Company\": company, \"Location\": location, \"Date\": date,\"Skills\" : skills ,\"Link\": link})\n",
        "        except AttributeError:\n",
        "            continue\n",
        "\n",
        "    return jobs\n",
        "\n",
        "# قائمة لحفظ جميع الوظائف\n",
        "all_jobs = []\n",
        "\n",
        "# بدء جمع البيانات من الصفحات بتقسيمها من صفحة ١ ل ٢٠ مثلًا وهكذا\n",
        "for page_number in range(50,54):\n",
        "    # بناء رابط الصفحة بناءً على معلمة start\n",
        "    url = f\"{base_url}&start={(page_number)}\"\n",
        "    print(f\"جاري جمع البيانات من الصفحة {page_number}...\")\n",
        "\n",
        "    # جمع الوظائف من الصفحة الحالية\n",
        "    jobs = get_jobs_from_page(url)\n",
        "\n",
        "\n",
        "    # إضافة الوظائف إلى القائمة\n",
        "    all_jobs.extend(jobs)\n",
        "\n",
        "\n",
        "# تحويل البيانات إلى DataFrame\n",
        "df = pd.DataFrame(all_jobs)\n",
        "\n",
        "# حفظ البيانات إلى ملف Excel\n",
        "df.to_excel(\"Wuzzuf.xlsx\", index=False)\n",
        "\n",
        "print(\"تم جمع البيانات من جميع الصفحات وحفظها في ملف Excel.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcNogjtYDm3b",
        "outputId": "240d4917-f302-49b5-ca45-638e0c776cc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "جاري جمع البيانات من الصفحة 50...\n",
            "جاري جمع البيانات من الصفحة 51...\n",
            "جاري جمع البيانات من الصفحة 52...\n",
            "جاري جمع البيانات من الصفحة 53...\n",
            "تم جمع البيانات من جميع الصفحات وحفظها في ملف Excel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# URL الأساسي للبحث عن وظائف في مجال الاتصالات والتكنولوجيا\n",
        "base_url = \"https://wuzzuf.net/a/Engineering-Telecom-Technology-Jobs-in-Egypt?start=\"\n",
        "\n",
        "# إضافة User-Agent لتجنب الحظر\n",
        "headers = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
        "}\n",
        "\n",
        "# وظيفة لجمع البيانات من صفحة واحدة\n",
        "def get_jobs_from_page(url):\n",
        "    response = requests.get(url, headers=headers)\n",
        "    soup = BeautifulSoup(response.content, \"lxml\")\n",
        "\n",
        "    jobs = []\n",
        "    for job_card in soup.find_all(\"div\", class_=\"css-1gatmva e1v1l3u10\"):\n",
        "        try:\n",
        "            title = job_card.find(\"h2\", class_=\"css-m604qf\").text.strip()  # عنوان الوظيفة\n",
        "            company = job_card.find(\"a\", class_=\"css-17s97q8\").text.strip()  # اسم الشركة\n",
        "            location = job_card.find(\"span\", class_=\"css-5wys0k\").text.strip()  # الموقع\n",
        "            date = job_card.find(\"div\", class_=\"css-do6t5g\").text.strip()  # تاريخ النشر\n",
        "            skills = job_card.find(\"div\", class_=\"css-y4udm8\").text.strip()  # المهارات المطلوبة\n",
        "            link = \"https://wuzzuf.net\" + job_card.find(\"a\", class_=\"css-o171kl\")[\"href\"]  # رابط الوظيفة\n",
        "            jobs.append({\"Job Title\": title, \"Company\": company, \"Location\": location, \"Date\": date,\"Skills\" : skills ,\"Link\": link})\n",
        "        except AttributeError:\n",
        "            continue\n",
        "\n",
        "    return jobs\n",
        "\n",
        "# قائمة لحفظ جميع الوظائف\n",
        "all_jobs = []\n",
        "\n",
        "# بدء جمع البيانات من الصفحات\n",
        "for page_number in range(20,30):\n",
        "    # بناء رابط الصفحة بناءً على معلمة start\n",
        "    url = f\"{base_url}{(page_number)}\"\n",
        "    print(f\"جاري جمع البيانات من الصفحة {page_number}...\")\n",
        "\n",
        "    # جمع الوظائف من الصفحة الحالية\n",
        "    jobs = get_jobs_from_page(url)\n",
        "\n",
        "\n",
        "    # إضافة الوظائف إلى القائمة\n",
        "    all_jobs.extend(jobs)\n",
        "\n",
        "\n",
        "# تحويل البيانات إلى DataFrame\n",
        "df = pd.DataFrame(all_jobs)\n",
        "\n",
        "# حفظ البيانات إلى ملف Excel\n",
        "df.to_excel(\"Wuzzuf_Engineering_Telecom_Jobs_All_Pages.xlsx\", index=False)\n",
        "\n",
        "print(\"تم جمع البيانات من جميع الصفحات وحفظها في ملف Excel.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72wPmQgkzBp_",
        "outputId": "a12ac571-8df8-4501-93fd-d91ef7547726"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "جاري جمع البيانات من الصفحة 20...\n",
            "جاري جمع البيانات من الصفحة 21...\n",
            "جاري جمع البيانات من الصفحة 22...\n",
            "جاري جمع البيانات من الصفحة 23...\n",
            "جاري جمع البيانات من الصفحة 24...\n",
            "جاري جمع البيانات من الصفحة 25...\n",
            "جاري جمع البيانات من الصفحة 26...\n",
            "جاري جمع البيانات من الصفحة 27...\n",
            "جاري جمع البيانات من الصفحة 28...\n",
            "جاري جمع البيانات من الصفحة 29...\n",
            "تم جمع البيانات من جميع الصفحات وحفظها في ملف Excel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_url = \"https://wuzzuf.net/a/Analyst-Research-Jobs-in-Egypt?start=\"\n",
        "\n",
        "headers = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
        "}\n",
        "\n",
        "def get_jobs_from_page(url):\n",
        "  response = requests.get(url, headers=headers)\n",
        "  soup = BeautifulSoup(response.content, \"lxml\")\n",
        "\n",
        "  jobs = []\n",
        "\n",
        "  for job_card in soup.find_all(\"div\", class_=\"css-1gatmva e1v1l3u10\"):\n",
        "    try:\n",
        "      title = job_card.find(\"h2\", class_=\"css-m604qf\").text.strip()\n",
        "      company = job_card.find(\"a\", class_=\"css-17s97q8\").text.strip()\n",
        "      location = job_card.find(\"span\", class_=\"css-5wys0k\").text.strip()\n",
        "      date = job_card.find(\"div\", class_ = \"css-4c4ojb\").text.strip()\n",
        "      skills = job_card.find(\"div\", class_= \"css-y4udm8\").text.strip()\n",
        "      link = \"https://wuzzuf.net\"+ job_card.find(\"a\", class_=\"css-o171kl\")[\"href\"]\n",
        "      jobs.append({\"Job Title\": title, \"Company\": company, \"Location\": location, \"Date\": date,\"Skills\" : skills ,\"Link\": link})\n",
        "    except AttributeError:\n",
        "      continue\n",
        "\n",
        "  return jobs\n",
        "\n",
        "all_jobs = []\n",
        "\n",
        "\n",
        "for page_number in range(8):\n",
        "  url = f\"{base_url}{page_number}\"\n",
        "  print(f\"Collecting data from page {page_number}...\")\n",
        "\n",
        "  jobs = get_jobs_from_page(url)\n",
        "\n",
        "  all_jobs.extend(jobs)\n",
        "\n",
        "\n",
        "df = pd.DataFrame(all_jobs)\n",
        "\n",
        "df.to_excel(\"Wuzzuf_Analyst_Research_Jobs_All_Pages.xlsx\", index=False)\n",
        "\n",
        "print(\"Data collected from all pages and saved to Excel file.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5V2ZFzC-u1n",
        "outputId": "d45b00cc-4572-4e27-a770-7f7aa814f64f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting data from page 0...\n",
            "Collecting data from page 1...\n",
            "Collecting data from page 2...\n",
            "Collecting data from page 3...\n",
            "Collecting data from page 4...\n",
            "Collecting data from page 5...\n",
            "Collecting data from page 6...\n",
            "Collecting data from page 7...\n",
            "Data collected from all pages and saved to Excel file.\n"
          ]
        }
      ]
    }
  ]
}